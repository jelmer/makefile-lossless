use crate::lex::lex;
use crate::SyntaxKind;
use crate::SyntaxKind::*;
use rowan::ast::AstNode;
use std::str::FromStr;

#[derive(Debug)]
/// An error that can occur when parsing a makefile
pub enum Error {
    /// An I/O error occurred
    Io(std::io::Error),

    /// A parse error occurred
    Parse(ParseError),
}

impl std::fmt::Display for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match &self {
            Error::Io(e) => write!(f, "IO error: {}", e),
            Error::Parse(e) => write!(f, "Parse error: {}", e),
        }
    }
}

impl From<std::io::Error> for Error {
    fn from(e: std::io::Error) -> Self {
        Error::Io(e)
    }
}

impl std::error::Error for Error {}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
/// An error that occurred while parsing a makefile
pub struct ParseError {
    errors: Vec<ErrorInfo>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
/// Information about a specific parsing error
pub struct ErrorInfo {
    message: String,
    line: usize,
    context: String,
}

impl std::fmt::Display for ParseError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        for err in &self.errors {
            writeln!(f, "Error at line {}: {}", err.line, err.message)?;
            writeln!(f, "{}| {}", err.line, err.context)?;
        }
        Ok(())
    }
}

impl std::error::Error for ParseError {}

impl From<ParseError> for Error {
    fn from(e: ParseError) -> Self {
        Error::Parse(e)
    }
}

/// Second, implementing the `Language` trait teaches rowan to convert between
/// these two SyntaxKind types, allowing for a nicer SyntaxNode API where
/// "kinds" are values from our `enum SyntaxKind`, instead of plain u16 values.
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum Lang {}
impl rowan::Language for Lang {
    type Kind = SyntaxKind;
    fn kind_from_raw(raw: rowan::SyntaxKind) -> Self::Kind {
        unsafe { std::mem::transmute::<u16, SyntaxKind>(raw.0) }
    }
    fn kind_to_raw(kind: Self::Kind) -> rowan::SyntaxKind {
        kind.into()
    }
}

/// GreenNode is an immutable tree, which is cheap to change,
/// but doesn't contain offsets and parent pointers.
use rowan::GreenNode;

/// You can construct GreenNodes by hand, but a builder
/// is helpful for top-down parsers: it maintains a stack
/// of currently in-progress nodes
use rowan::GreenNodeBuilder;

/// The parse results are stored as a "green tree".
/// We'll discuss working with the results later
#[derive(Debug)]
struct Parse {
    green_node: GreenNode,
    #[allow(unused)]
    errors: Vec<ErrorInfo>,
}

fn parse(text: &str) -> Parse {
    struct Parser {
        /// input tokens, including whitespace,
        /// in *reverse* order.
        tokens: Vec<(SyntaxKind, String)>,
        /// the in-progress tree.
        builder: GreenNodeBuilder<'static>,
        /// the list of syntax errors we've accumulated
        /// so far.
        errors: Vec<ErrorInfo>,
        /// The original text
        original_text: String,
    }

    impl Parser {
        fn error(&mut self, msg: String) {
            self.builder.start_node(ERROR.into());

            let (line, context) = if self.current() == Some(INDENT) {
                // For indented lines, report the error on the next line
                let lines: Vec<&str> = self.original_text.lines().collect();
                let tab_line = lines
                    .iter()
                    .enumerate()
                    .find(|(_, line)| line.starts_with('\t'))
                    .map(|(i, _)| i + 1)
                    .unwrap_or(1);

                // Use the next line as context if available
                let next_line = tab_line + 1;
                if next_line <= lines.len() {
                    (next_line, lines[next_line - 1].to_string())
                } else {
                    (tab_line, lines[tab_line - 1].to_string())
                }
            } else {
                let line = self.get_line_number_for_position(self.tokens.len());
                (line, self.get_context_for_line(line))
            };

            let message = if self.current() == Some(INDENT) && !msg.contains("indented") {
                if self.tokens.len() > 0 && self.tokens[self.tokens.len() - 1].0 == IDENTIFIER {
                    "expected ':'".to_string()
                } else {
                    "indented line not part of a rule".to_string()
                }
            } else {
                msg
            };

            self.errors.push(ErrorInfo {
                message,
                line,
                context,
            });

            if self.current().is_some() {
                self.bump();
            }
            self.builder.finish_node();
        }

        fn get_line_number_for_position(&self, position: usize) -> usize {
            if position >= self.tokens.len() {
                return self.original_text.matches('\n').count() + 1;
            }

            // Count newlines in the processed text up to this position
            self.tokens[0..position]
                .iter()
                .filter(|(kind, _)| *kind == NEWLINE)
                .count()
                + 1
        }

        fn get_context_for_line(&self, line_number: usize) -> String {
            self.original_text
                .lines()
                .nth(line_number - 1)
                .unwrap_or("")
                .to_string()
        }

        fn parse_recipe_line(&mut self) {
            self.builder.start_node(RECIPE.into());

            // Check for and consume the indent
            if self.current() != Some(INDENT) {
                self.error("recipe line must start with a tab".into());
                self.builder.finish_node();
                return;
            }
            self.bump();

            // Parse the recipe content
            match self.current() {
                Some(TEXT) => self.bump(),
                Some(NEWLINE) => {
                    // Empty recipe line (just a tab) is valid
                    self.bump();
                }
                Some(kind) => {
                    self.error(format!("unexpected token in recipe: {:?}", kind));
                    self.bump();
                }
                None => {
                    // End of file after tab is valid
                }
            }

            // Ensure proper line ending if we're not at EOF
            if self.current().is_some() && self.current() != Some(NEWLINE) {
                self.error("recipe line must end with a newline".into());
                self.skip_until_newline();
            } else if self.current() == Some(NEWLINE) {
                self.bump();
            }

            self.builder.finish_node();
        }

        fn parse_rule_target(&mut self) -> bool {
            match self.current() {
                Some(IDENTIFIER) => {
                    self.bump();
                    true
                }
                Some(DOLLAR) => {
                    self.parse_variable_reference();
                    true
                }
                _ => {
                    self.error("expected rule target".into());
                    false
                }
            }
        }

        fn parse_rule_dependencies(&mut self) {
            self.builder.start_node(EXPR.into());
            while self.current().is_some() && self.current() != Some(NEWLINE) {
                self.bump();
            }
            self.builder.finish_node();
        }

        fn parse_rule_recipes(&mut self) {
            loop {
                match self.current() {
                    Some(INDENT) => {
                        self.parse_recipe_line();
                    }
                    Some(NEWLINE) => {
                        self.bump();
                        break;
                    }
                    _ => break,
                }
            }
        }

        fn find_and_consume_colon(&mut self) -> bool {
            // Skip whitespace before colon
            self.skip_ws();

            // Check if we're at a colon
            if self.current() == Some(OPERATOR) && self.tokens.last().unwrap().1 == ":" {
                self.bump();
                return true;
            }

            // Look ahead for a colon
            let has_colon = self
                .tokens
                .iter()
                .rev()
                .any(|(kind, text)| *kind == OPERATOR && text == ":");

            if has_colon {
                // Consume tokens until we find the colon
                while self.current().is_some() {
                    if self.current() == Some(OPERATOR) && self.tokens.last().unwrap().1 == ":" {
                        self.bump();
                        return true;
                    }
                    self.bump();
                }
            }

            self.error("expected ':'".into());
            false
        }

        fn parse_rule(&mut self) {
            self.builder.start_node(RULE.into());

            // Parse target
            self.skip_ws();
            let has_target = self.parse_rule_target();

            // Find and consume the colon
            let has_colon = if has_target {
                self.find_and_consume_colon()
            } else {
                false
            };

            // Parse dependencies if we found both target and colon
            if has_target && has_colon {
                self.skip_ws();
                self.parse_rule_dependencies();
                self.expect_eol();

                // Parse recipe lines
                self.parse_rule_recipes();
            }

            self.builder.finish_node();
        }

        fn parse_comment(&mut self) {
            self.expect(COMMENT);
            self.expect_eol();
        }

        fn parse_assignment(&mut self) {
            self.builder.start_node(VARIABLE.into());

            // Handle export prefix if present
            self.skip_ws();
            if self.current() == Some(IDENTIFIER) && self.tokens.last().unwrap().1 == "export" {
                self.bump();
                self.skip_ws();
            }

            // Parse variable name
            match self.current() {
                Some(IDENTIFIER) => self.bump(),
                Some(DOLLAR) => self.parse_variable_reference(),
                _ => {
                    self.error("expected variable name".into());
                    self.builder.finish_node();
                    return;
                }
            }

            // Skip whitespace and parse operator
            self.skip_ws();
            match self.current() {
                Some(OPERATOR) => {
                    let op = self.tokens.last().unwrap().1.clone();
                    if ["=", ":=", "::=", ":::=", "+=", "?=", "!="].contains(&op.as_str()) {
                        self.bump();
                        self.skip_ws();

                        // Parse value
                        self.builder.start_node(EXPR.into());
                        while self.current().is_some() && self.current() != Some(NEWLINE) {
                            self.bump();
                        }
                        self.builder.finish_node();

                        // Expect newline
                        if self.current() == Some(NEWLINE) {
                            self.bump();
                        } else {
                            self.error("expected newline after variable value".into());
                        }
                    } else {
                        self.error(format!("invalid assignment operator: {}", op));
                    }
                }
                _ => self.error("expected assignment operator".into()),
            }

            self.builder.finish_node();
        }

        fn parse_variable_reference(&mut self) {
            self.bump(); // Consume $
            if self.current() == Some(LPAREN) {
                self.bump(); // Consume (
                let mut paren_depth = 1;
                while paren_depth > 0 && self.current().is_some() {
                    match self.current() {
                        Some(LPAREN) => {
                            paren_depth += 1;
                            self.bump();
                        }
                        Some(RPAREN) => {
                            paren_depth -= 1;
                            self.bump();
                        }
                        Some(_) => self.bump(),
                        None => {
                            self.error("unclosed variable reference".into());
                            break;
                        }
                    }
                }
            } else {
                self.error("expected ( after $ in variable reference".into());
            }
        }

        fn parse_conditional_keyword(&mut self) -> Option<String> {
            if self.current() != Some(IDENTIFIER) {
                self.error("expected conditional keyword (ifdef, ifndef, ifeq, or ifneq)".into());
                return None;
            }

            let token = self.tokens.last().unwrap().1.clone();
            if !["ifdef", "ifndef", "ifeq", "ifneq"].contains(&token.as_str()) {
                self.error(format!("unknown conditional directive: {}", token));
                return None;
            }

            self.bump();
            Some(token)
        }

        fn parse_simple_condition(&mut self) {
            self.builder.start_node(EXPR.into());
            if self.current() == Some(IDENTIFIER) {
                self.bump();
            } else {
                self.error("expected variable name".into());
            }
            self.builder.finish_node();
            self.expect_eol();
        }

        fn parse_elif_condition(&mut self) {
            self.skip_ws();
            match self.current() {
                Some(IDENTIFIER) => {
                    self.builder.start_node(EXPR.into());
                    self.bump();
                    self.builder.finish_node();
                }
                Some(LPAREN) => self.parse_parenthesized_expr(),
                _ => self.error("expected condition after elif".into()),
            }
            self.skip_ws();
            self.expect_eol();
        }

        fn handle_conditional_token(&mut self, token: &str, depth: &mut i32) -> bool {
            match token {
                "endif" => {
                    *depth -= 1;
                    self.bump();
                    self.skip_ws();
                    self.expect_eol();
                    true
                }
                "else" | "elif" if *depth == 1 => {
                    self.bump();
                    if token == "elif" {
                        self.parse_elif_condition();
                    } else {
                        self.skip_ws();
                        self.expect_eol();
                    }
                    true
                }
                s if s.starts_with("if") => {
                    self.parse_conditional();
                    true
                }
                _ => false,
            }
        }

        fn parse_conditional(&mut self) {
            self.builder.start_node(CONDITIONAL.into());

            // Parse the conditional keyword
            let Some(token) = self.parse_conditional_keyword() else {
                self.skip_until_newline();
                self.builder.finish_node();
                return;
            };

            // Skip whitespace after keyword
            self.skip_ws();

            // Parse the condition based on keyword type
            match token.as_str() {
                "ifdef" | "ifndef" => {
                    self.parse_simple_condition();
                }
                "ifeq" | "ifneq" => {
                    self.parse_parenthesized_expr();
                }
                _ => unreachable!("Invalid conditional token"),
            }

            // Parse the conditional body
            let mut depth = 1;
            while depth > 0 && self.current().is_some() {
                match self.current() {
                    None => {
                        self.error("unterminated conditional (missing endif)".into());
                        break;
                    }
                    Some(IDENTIFIER) => {
                        let token = self.tokens.last().unwrap().1.clone();
                        if !self.handle_conditional_token(&token, &mut depth) {
                            self.parse_normal_content();
                        }
                    }
                    Some(INDENT) => self.parse_recipe_line(),
                    Some(WHITESPACE) => self.bump(),
                    Some(COMMENT) => self.parse_comment(),
                    Some(NEWLINE) => self.bump(),
                    Some(DOLLAR) => self.parse_normal_content(),
                    Some(_) => {
                        self.error(format!(
                            "unexpected token in conditional block: {:?}",
                            self.current()
                        ));
                        self.bump();
                    }
                }
            }

            self.builder.finish_node();
        }

        // Helper method to parse a parenthesized expression
        fn parse_parenthesized_expr(&mut self) {
            self.builder.start_node(EXPR.into());

            if self.current() != Some(LPAREN) {
                self.error("expected opening parenthesis".into());
                self.builder.finish_node();
                return;
            }

            let mut paren_count = 1;
            self.bump(); // Consume opening paren

            while paren_count > 0 && self.current().is_some() {
                match self.current() {
                    Some(LPAREN) => {
                        paren_count += 1;
                        self.bump();
                    }
                    Some(RPAREN) => {
                        paren_count -= 1;
                        self.bump();
                    }
                    Some(_) => self.bump(),
                    None => {
                        self.error("unclosed parenthesis".into());
                        break;
                    }
                }
            }

            self.skip_ws();
            self.expect_eol();
            self.builder.finish_node();
        }

        // Helper to parse normal content (either assignment or rule)
        fn parse_normal_content(&mut self) {
            // Skip any leading whitespace
            self.skip_ws();

            // Check if this could be a variable assignment
            if self.is_assignment_line() {
                self.parse_assignment();
            } else {
                // Try to handle as a rule
                self.parse_rule();
            }
        }

        fn parse_include(&mut self) {
            self.builder.start_node(INCLUDE.into());

            // Consume include keyword variant
            if self.current() != Some(IDENTIFIER)
                || (!["include", "-include", "sinclude"]
                    .contains(&self.tokens.last().unwrap().1.as_str()))
            {
                self.error("expected include directive".into());
                self.builder.finish_node();
                return;
            }
            self.bump();
            self.skip_ws();

            // Parse file paths
            self.builder.start_node(EXPR.into());
            let mut found_path = false;

            while self.current().is_some() && self.current() != Some(NEWLINE) {
                match self.current() {
                    Some(WHITESPACE) => self.skip_ws(),
                    Some(DOLLAR) => {
                        found_path = true;
                        self.parse_variable_reference();
                    }
                    Some(_) => {
                        // Accept any token as part of the path
                        found_path = true;
                        self.bump();
                    }
                    None => break,
                }
            }

            if !found_path {
                self.error("expected file path after include".into());
            }

            self.builder.finish_node();

            // Expect newline
            if self.current() == Some(NEWLINE) {
                self.bump();
            } else if self.current().is_some() {
                self.error("expected newline after include".into());
                self.skip_until_newline();
            }

            self.builder.finish_node();
        }

        fn parse_identifier_token(&mut self) -> bool {
            let token = self.tokens.last().unwrap().1.clone();

            // Handle special cases first
            if token.starts_with("%") {
                self.parse_rule();
                return true;
            }

            if token.starts_with("if") {
                self.parse_conditional();
                return true;
            }

            if token == "include" || token == "-include" || token == "sinclude" {
                self.parse_include();
                return true;
            }

            // Handle normal content (assignment or rule)
            self.parse_normal_content();
            true
        }

        fn parse_token(&mut self) -> bool {
            match self.current() {
                None => false,
                Some(IDENTIFIER) => self.parse_identifier_token(),
                Some(DOLLAR) => {
                    self.parse_normal_content();
                    true
                }
                Some(NEWLINE) => {
                    self.bump();
                    true
                }
                Some(COMMENT) => {
                    self.parse_comment();
                    true
                }
                Some(WHITESPACE) => {
                    self.skip_ws();
                    true
                }
                Some(INDENT) => {
                    self.error("indented line not part of a rule".into());
                    self.bump();
                    true
                }
                Some(kind) => {
                    self.error(format!("unexpected token {:?}", kind));
                    self.bump();
                    true
                }
            }
        }

        fn parse(mut self) -> Parse {
            self.builder.start_node(ROOT.into());

            while self.parse_token() {}

            self.builder.finish_node();

            Parse {
                green_node: self.builder.finish(),
                errors: self.errors,
            }
        }

        // Simplify the is_assignment_line method by making it more direct
        fn is_assignment_line(&mut self) -> bool {
            let assignment_ops = ["=", ":=", "::=", ":::=", "+=", "?=", "!="];
            let mut pos = self.tokens.len().saturating_sub(1);
            let mut seen_identifier = false;
            let mut seen_export = false;

            while pos > 0 {
                let (kind, text) = &self.tokens[pos];

                match kind {
                    NEWLINE => break,
                    IDENTIFIER if text == "export" => seen_export = true,
                    IDENTIFIER if !seen_identifier => seen_identifier = true,
                    OPERATOR if assignment_ops.contains(&text.as_str()) => {
                        return seen_identifier || seen_export
                    }
                    OPERATOR if text == ":" => return false, // It's a rule if we see a colon first
                    WHITESPACE => (),
                    _ if seen_export => return true, // Everything after export is part of the assignment
                    _ => return false,
                }
                pos = pos.saturating_sub(1);
            }
            false
        }

        /// Advance one token, adding it to the current branch of the tree builder.
        fn bump(&mut self) {
            let (kind, text) = self.tokens.pop().unwrap();
            self.builder.token(kind.into(), text.as_str());
        }
        /// Peek at the first unprocessed token
        fn current(&self) -> Option<SyntaxKind> {
            self.tokens.last().map(|(kind, _)| *kind)
        }

        fn expect_eol(&mut self) {
            match self.current() {
                Some(NEWLINE) => {
                    self.bump();
                }
                None => {}
                n => {
                    self.error(format!("expected newline, got {:?}", n));
                }
            }
        }

        fn expect(&mut self, expected: SyntaxKind) {
            if self.current() != Some(expected) {
                self.error(format!("expected {:?}, got {:?}", expected, self.current()));
            } else {
                self.bump();
            }
        }
        fn skip_ws(&mut self) {
            while self.current() == Some(WHITESPACE) {
                self.bump()
            }
        }

        fn skip_until_newline(&mut self) {
            while self.current().is_some() && self.current() != Some(NEWLINE) {
                self.bump();
            }
            if self.current() == Some(NEWLINE) {
                self.bump();
            }
        }
    }

    let mut tokens = lex(text);
    tokens.reverse();
    Parser {
        tokens,
        builder: GreenNodeBuilder::new(),
        errors: Vec::new(),
        original_text: text.to_string(),
    }
    .parse()
}

/// To work with the parse results we need a view into the
/// green tree - the Syntax tree.
/// It is also immutable, like a GreenNode,
/// but it contains parent pointers, offsets, and
/// has identity semantics.

type SyntaxNode = rowan::SyntaxNode<Lang>;
#[allow(unused)]
type SyntaxToken = rowan::SyntaxToken<Lang>;
#[allow(unused)]
type SyntaxElement = rowan::NodeOrToken<SyntaxNode, SyntaxToken>;

impl Parse {
    fn syntax(&self) -> SyntaxNode {
        SyntaxNode::new_root_mut(self.green_node.clone())
    }

    fn root(&self) -> Makefile {
        Makefile::cast(self.syntax()).unwrap()
    }
}

macro_rules! ast_node {
    ($ast:ident, $kind:ident) => {
        #[derive(PartialEq, Eq, Hash)]
        #[repr(transparent)]
        /// An AST node for $ast
        pub struct $ast(SyntaxNode);

        impl AstNode for $ast {
            type Language = Lang;

            fn can_cast(kind: SyntaxKind) -> bool {
                kind == $kind
            }

            fn cast(syntax: SyntaxNode) -> Option<Self> {
                if Self::can_cast(syntax.kind()) {
                    Some(Self(syntax))
                } else {
                    None
                }
            }

            fn syntax(&self) -> &SyntaxNode {
                &self.0
            }
        }

        impl core::fmt::Display for $ast {
            fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> Result<(), core::fmt::Error> {
                write!(f, "{}", self.0.text())
            }
        }
    };
}

ast_node!(Makefile, ROOT);
ast_node!(Rule, RULE);
ast_node!(Identifier, IDENTIFIER);
ast_node!(VariableDefinition, VARIABLE);
ast_node!(Include, INCLUDE);

impl VariableDefinition {
    /// Get the name of the variable definition
    pub fn name(&self) -> Option<String> {
        self.syntax().children_with_tokens().find_map(|it| {
            it.as_token().and_then(|it| {
                if it.kind() == IDENTIFIER && it.text() != "export" {
                    Some(it.text().to_string())
                } else {
                    None
                }
            })
        })
    }

    /// Get the raw value of the variable definition
    pub fn raw_value(&self) -> Option<String> {
        self.syntax()
            .children()
            .find(|it| it.kind() == EXPR)
            .map(|it| it.text().to_string())
    }
}

impl Makefile {
    /// Create a new empty makefile
    pub fn new() -> Makefile {
        let mut builder = GreenNodeBuilder::new();

        builder.start_node(ROOT.into());
        builder.finish_node();

        let syntax = SyntaxNode::new_root_mut(builder.finish());
        Makefile(syntax)
    }

    /// Read a changelog file from a reader
    pub fn read<R: std::io::Read>(mut r: R) -> Result<Makefile, Error> {
        let mut buf = String::new();
        r.read_to_string(&mut buf)?;
        Ok(buf.parse()?)
    }

    /// Read makefile from a reader, but allow syntax errors
    pub fn read_relaxed<R: std::io::Read>(mut r: R) -> Result<Makefile, Error> {
        let mut buf = String::new();
        r.read_to_string(&mut buf)?;

        let parsed = parse(&buf);
        Ok(parsed.root())
    }

    /// Retrieve the rules in the makefile
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Makefile;
    /// let makefile: Makefile = "rule: dependency\n\tcommand\n".parse().unwrap();
    /// assert_eq!(makefile.rules().count(), 1);
    /// ```
    pub fn rules(&self) -> impl Iterator<Item = Rule> {
        self.syntax().children().filter_map(Rule::cast)
    }

    /// Get all rules that have a specific target
    pub fn rules_by_target<'a>(&'a self, target: &'a str) -> impl Iterator<Item = Rule> + 'a {
        self.rules()
            .filter(move |rule| rule.targets().any(|t| t == target))
    }

    /// Get all variable definitions in the makefile
    pub fn variable_definitions(&self) -> impl Iterator<Item = VariableDefinition> {
        self.syntax()
            .children()
            .filter_map(VariableDefinition::cast)
    }

    /// Add a new rule to the makefile
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Makefile;
    /// let mut makefile = Makefile::new();
    /// makefile.add_rule("rule");
    /// assert_eq!(makefile.to_string(), "rule:\n");
    /// ```
    pub fn add_rule(&mut self, target: &str) -> Rule {
        let mut builder = GreenNodeBuilder::new();
        builder.start_node(RULE.into());
        builder.token(IDENTIFIER.into(), target);
        builder.token(OPERATOR.into(), ":");
        builder.token(NEWLINE.into(), "\n");
        builder.finish_node();

        let syntax = SyntaxNode::new_root_mut(builder.finish());
        let pos = self.0.children_with_tokens().count();
        self.0.splice_children(pos..pos, vec![syntax.into()]);
        Rule(self.0.children().nth(pos).unwrap())
    }

    /// Read the makefile
    pub fn from_reader<R: std::io::Read>(mut r: R) -> Result<Makefile, Error> {
        let mut buf = String::new();
        r.read_to_string(&mut buf)?;

        let parsed = parse(&buf);
        if !parsed.errors.is_empty() {
            Err(Error::Parse(ParseError {
                errors: parsed.errors,
            }))
        } else {
            Ok(parsed.root())
        }
    }

    /// Get all include directives in the makefile
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Makefile;
    /// let makefile: Makefile = "include config.mk\n-include .env\n".parse().unwrap();
    /// let includes = makefile.includes().collect::<Vec<_>>();
    /// assert_eq!(includes.len(), 2);
    /// ```
    pub fn includes(&self) -> impl Iterator<Item = Include> {
        self.syntax().children().filter_map(Include::cast)
    }

    /// Get all included file paths
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Makefile;
    /// let makefile: Makefile = "include config.mk\n-include .env\n".parse().unwrap();
    /// let paths = makefile.included_files().collect::<Vec<_>>();
    /// assert_eq!(paths, vec!["config.mk", ".env"]);
    /// ```
    pub fn included_files(&self) -> impl Iterator<Item = String> + '_ {
        self.includes().map(|include| {
            include
                .syntax()
                .children()
                .find(|node| node.kind() == EXPR)
                .map(|expr| expr.text().to_string().trim().to_string())
                .unwrap_or_default()
                .trim()
                .to_string()
        })
    }
}

impl FromStr for Rule {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let parsed = parse(s);

        if !parsed.errors.is_empty() {
            return Err(ParseError {
                errors: parsed.errors,
            });
        }

        let rules = parsed.root().rules().collect::<Vec<_>>();
        if rules.len() == 1 {
            Ok(rules.into_iter().next().unwrap())
        } else {
            Err(ParseError {
                errors: vec![ErrorInfo {
                    message: "expected a single rule".to_string(),
                    line: 1,
                    context: s.lines().next().unwrap_or("").to_string(),
                }],
            })
        }
    }
}

impl FromStr for Makefile {
    type Err = ParseError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let parsed = parse(s);
        if parsed.errors.is_empty() {
            Ok(parsed.root())
        } else {
            Err(ParseError {
                errors: parsed.errors,
            })
        }
    }
}

impl Rule {
    /// Targets of this rule
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Rule;
    ///
    /// let rule: Rule = "rule: dependency\n\tcommand".parse().unwrap();
    /// assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
    /// ```
    pub fn targets(&self) -> impl Iterator<Item = String> + '_ {
        let mut result = Vec::new();
        let mut tokens = self
            .syntax()
            .children_with_tokens()
            .take_while(|it| it.as_token().map_or(true, |t| t.kind() != OPERATOR))
            .peekable();

        while let Some(token) = tokens.next() {
            if let Some(t) = token.as_token() {
                if t.kind() == DOLLAR {
                    // Start of a variable reference - collect all tokens until )
                    let mut var_ref = String::new();
                    var_ref.push_str(t.text());

                    while let Some(next_token) = tokens.next() {
                        if let Some(nt) = next_token.as_token() {
                            var_ref.push_str(nt.text());
                            if nt.kind() == RPAREN {
                                break;
                            }
                        }
                    }
                    result.push(var_ref);
                } else if t.kind() == IDENTIFIER {
                    result.push(t.text().to_string());
                }
            }
        }
        result.into_iter()
    }

    /// Get the prerequisites in the rule
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Rule;
    /// let rule: Rule = "rule: dependency\n\tcommand".parse().unwrap();
    /// assert_eq!(rule.prerequisites().collect::<Vec<_>>(), vec!["dependency"]);
    /// ```
    pub fn prerequisites(&self) -> impl Iterator<Item = String> + '_ {
        self.syntax()
            .children()
            .find(|it| it.kind() == EXPR)
            .into_iter()
            .flat_map(|it| {
                let mut tokens = it.children_with_tokens().peekable();
                let mut result = Vec::new();

                while let Some(token) = tokens.next() {
                    if let Some(t) = token.as_token() {
                        if t.kind() == DOLLAR {
                            // Start of a variable reference - collect all tokens until )
                            let mut var_ref = String::new();
                            var_ref.push_str(t.text());

                            while let Some(next_token) = tokens.next() {
                                if let Some(nt) = next_token.as_token() {
                                    var_ref.push_str(nt.text());
                                    if nt.kind() == RPAREN {
                                        break;
                                    }
                                }
                            }
                            result.push(var_ref);
                        } else if t.kind() == IDENTIFIER {
                            result.push(t.text().to_string());
                        }
                    }
                }
                result.into_iter()
            })
    }

    /// Get the commands in the rule
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Rule;
    /// let rule: Rule = "rule: dependency\n\tcommand".parse().unwrap();
    /// assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command"]);
    /// ```
    pub fn recipes(&self) -> impl Iterator<Item = String> {
        self.syntax()
            .children()
            .filter(|it| it.kind() == RECIPE)
            .flat_map(|it| {
                it.children_with_tokens().filter_map(|it| {
                    it.as_token().and_then(|t| {
                        if t.kind() == TEXT {
                            Some(t.text().to_string())
                        } else {
                            None
                        }
                    })
                })
            })
    }

    /// Replace the command at index i with a new line
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Rule;
    /// let rule: Rule = "rule: dependency\n\tcommand".parse().unwrap();
    /// rule.replace_command(0, "new command");
    /// assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["new command"]);
    /// ```
    pub fn replace_command(&self, i: usize, line: &str) {
        // Find the RECIPE with index i, then replace the line in it
        let index = self
            .syntax()
            .children()
            .filter(|it| it.kind() == RECIPE)
            .nth(i)
            .expect("index out of bounds")
            .index();

        let mut builder = GreenNodeBuilder::new();
        builder.start_node(RECIPE.into());
        builder.token(INDENT.into(), "\t");
        builder.token(TEXT.into(), line);
        builder.token(NEWLINE.into(), "\n");
        builder.finish_node();

        let syntax = SyntaxNode::new_root_mut(builder.finish());
        self.0
            .splice_children(index..index + 1, vec![syntax.into()]);
    }

    /// Add a new command to the rule
    ///
    /// # Example
    /// ```
    /// use makefile_lossless::Rule;
    /// let rule: Rule = "rule: dependency\n\tcommand".parse().unwrap();
    /// rule.push_command("command2");
    /// assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command", "command2"]);
    /// ```
    pub fn push_command(&self, line: &str) {
        // Find the latest RECIPE entry, then append the new line after it.
        let index = self
            .0
            .children_with_tokens()
            .filter(|it| it.kind() == RECIPE)
            .last();

        let index = index.map_or_else(
            || self.0.children_with_tokens().count(),
            |it| it.index() + 1,
        );

        let mut builder = GreenNodeBuilder::new();
        builder.start_node(RECIPE.into());
        builder.token(INDENT.into(), "\t");
        builder.token(TEXT.into(), line);
        builder.token(NEWLINE.into(), "\n");
        builder.finish_node();
        let syntax = SyntaxNode::new_root_mut(builder.finish());

        self.0.splice_children(index..index, vec![syntax.into()]);
    }
}

impl Default for Makefile {
    fn default() -> Self {
        Self::new()
    }
}

impl Include {
    /// Get the raw path of the include directive
    pub fn path(&self) -> Option<String> {
        self.syntax()
            .children()
            .find(|it| it.kind() == EXPR)
            .map(|it| it.text().to_string().trim().to_string())
    }

    /// Check if this is an optional include (-include or sinclude)
    pub fn is_optional(&self) -> bool {
        let text = self.syntax().text();
        text.to_string().starts_with("-include") || text.to_string().starts_with("sinclude")
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_simple() {
        const SIMPLE: &str = r#"VARIABLE = value

rule: dependency
	command
"#;
        let parsed = parse(SIMPLE);
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert_eq!(
            format!("{:#?}", node),
            r#"ROOT@0..44
  VARIABLE@0..17
    IDENTIFIER@0..8 "VARIABLE"
    WHITESPACE@8..9 " "
    OPERATOR@9..10 "="
    WHITESPACE@10..11 " "
    EXPR@11..16
      IDENTIFIER@11..16 "value"
    NEWLINE@16..17 "\n"
  NEWLINE@17..18 "\n"
  RULE@18..44
    IDENTIFIER@18..22 "rule"
    OPERATOR@22..23 ":"
    WHITESPACE@23..24 " "
    EXPR@24..34
      IDENTIFIER@24..34 "dependency"
    NEWLINE@34..35 "\n"
    RECIPE@35..44
      INDENT@35..36 "\t"
      TEXT@36..43 "command"
      NEWLINE@43..44 "\n"
"#
        );

        let root = parsed.root();

        let mut rules = root.rules().collect::<Vec<_>>();
        assert_eq!(rules.len(), 1);
        let rule = rules.pop().unwrap();
        assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(rule.prerequisites().collect::<Vec<_>>(), vec!["dependency"]);
        assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command"]);

        let mut variables = root.variable_definitions().collect::<Vec<_>>();
        assert_eq!(variables.len(), 1);
        let variable = variables.pop().unwrap();
        assert_eq!(variable.name(), Some("VARIABLE".to_string()));
        assert_eq!(variable.raw_value(), Some("value".to_string()));
    }

    #[test]
    fn test_parse_export_assign() {
        const EXPORT: &str = r#"export VARIABLE := value
"#;
        let parsed = parse(EXPORT);
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert_eq!(
            format!("{:#?}", node),
            r#"ROOT@0..25
  VARIABLE@0..25
    IDENTIFIER@0..6 "export"
    WHITESPACE@6..7 " "
    IDENTIFIER@7..15 "VARIABLE"
    WHITESPACE@15..16 " "
    OPERATOR@16..18 ":="
    WHITESPACE@18..19 " "
    EXPR@19..24
      IDENTIFIER@19..24 "value"
    NEWLINE@24..25 "\n"
"#
        );

        let root = parsed.root();

        let mut variables = root.variable_definitions().collect::<Vec<_>>();
        assert_eq!(variables.len(), 1);
        let variable = variables.pop().unwrap();
        assert_eq!(variable.name(), Some("VARIABLE".to_string()));
        assert_eq!(variable.raw_value(), Some("value".to_string()));
    }

    #[test]
    fn test_parse_multiple_prerequisites() {
        const MULTIPLE_PREREQUISITES: &str = r#"rule: dependency1 dependency2
	command

"#;
        let parsed = parse(MULTIPLE_PREREQUISITES);
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert_eq!(
            format!("{:#?}", node),
            r#"ROOT@0..40
  RULE@0..40
    IDENTIFIER@0..4 "rule"
    OPERATOR@4..5 ":"
    WHITESPACE@5..6 " "
    EXPR@6..29
      IDENTIFIER@6..17 "dependency1"
      WHITESPACE@17..18 " "
      IDENTIFIER@18..29 "dependency2"
    NEWLINE@29..30 "\n"
    RECIPE@30..39
      INDENT@30..31 "\t"
      TEXT@31..38 "command"
      NEWLINE@38..39 "\n"
    NEWLINE@39..40 "\n"
"#
        );
        let root = parsed.root();

        let rule = root.rules().next().unwrap();
        assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(
            rule.prerequisites().collect::<Vec<_>>(),
            vec!["dependency1", "dependency2"]
        );
        assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command"]);
    }

    #[test]
    fn test_add_rule() {
        let mut makefile = Makefile::new();
        let rule = makefile.add_rule("rule");
        assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(
            rule.prerequisites().collect::<Vec<_>>(),
            Vec::<String>::new()
        );

        assert_eq!(makefile.to_string(), "rule:\n");
    }

    #[test]
    fn test_push_command() {
        let mut makefile = Makefile::new();
        let rule = makefile.add_rule("rule");
        rule.push_command("command");
        assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command"]);

        assert_eq!(makefile.to_string(), "rule:\n\tcommand\n");

        rule.push_command("command2");
        assert_eq!(
            rule.recipes().collect::<Vec<_>>(),
            vec!["command", "command2"]
        );

        assert_eq!(makefile.to_string(), "rule:\n\tcommand\n\tcommand2\n");
    }

    #[test]
    fn test_replace_command() {
        let mut makefile = Makefile::new();
        let rule = makefile.add_rule("rule");
        rule.push_command("command");
        rule.push_command("command2");
        assert_eq!(
            rule.recipes().collect::<Vec<_>>(),
            vec!["command", "command2"]
        );

        rule.replace_command(0, "new command");
        assert_eq!(
            rule.recipes().collect::<Vec<_>>(),
            vec!["new command", "command2"]
        );

        assert_eq!(makefile.to_string(), "rule:\n\tnew command\n\tcommand2\n");
    }

    #[test]
    fn test_parse_rule_without_newline() {
        let rule = "rule: dependency\n\tcommand".parse::<Rule>().unwrap();
        assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(rule.recipes().collect::<Vec<_>>(), vec!["command"]);
        let rule = "rule: dependency".parse::<Rule>().unwrap();
        assert_eq!(rule.targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(rule.recipes().collect::<Vec<_>>(), Vec::<String>::new());
    }

    #[test]
    fn test_parse_makefile_without_newline() {
        let makefile = "rule: dependency\n\tcommand".parse::<Makefile>().unwrap();
        assert_eq!(makefile.rules().count(), 1);
    }

    #[test]
    fn test_from_reader() {
        let makefile = Makefile::from_reader("rule: dependency\n\tcommand".as_bytes()).unwrap();
        assert_eq!(makefile.rules().count(), 1);
    }

    #[test]
    fn test_parse_with_tab_after_last_newline() {
        let makefile = Makefile::from_reader("rule: dependency\n\tcommand\n\t".as_bytes()).unwrap();
        assert_eq!(makefile.rules().count(), 1);
    }

    #[test]
    fn test_parse_with_space_after_last_newline() {
        let makefile = Makefile::from_reader("rule: dependency\n\tcommand\n ".as_bytes()).unwrap();
        assert_eq!(makefile.rules().count(), 1);
    }

    #[test]
    fn test_parse_with_comment_after_last_newline() {
        let makefile =
            Makefile::from_reader("rule: dependency\n\tcommand\n#comment".as_bytes()).unwrap();
        assert_eq!(makefile.rules().count(), 1);
    }

    #[test]
    fn test_parse_with_variable_rule() {
        let makefile =
            Makefile::from_reader("RULE := rule\n$(RULE): dependency\n\tcommand".as_bytes())
                .unwrap();

        // Check variable definition
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 1);
        assert_eq!(vars[0].name(), Some("RULE".to_string()));
        assert_eq!(vars[0].raw_value(), Some("rule".to_string()));

        // Check rule
        let rules = makefile.rules().collect::<Vec<_>>();
        assert_eq!(rules.len(), 1);
        assert_eq!(rules[0].targets().collect::<Vec<_>>(), vec!["$(RULE)"]);
        assert_eq!(
            rules[0].prerequisites().collect::<Vec<_>>(),
            vec!["dependency"]
        );
        assert_eq!(rules[0].recipes().collect::<Vec<_>>(), vec!["command"]);
    }

    #[test]
    fn test_parse_with_variable_dependency() {
        let makefile =
            Makefile::from_reader("DEP := dependency\nrule: $(DEP)\n\tcommand".as_bytes()).unwrap();

        // Check variable definition
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 1);
        assert_eq!(vars[0].name(), Some("DEP".to_string()));
        assert_eq!(vars[0].raw_value(), Some("dependency".to_string()));

        // Check rule
        let rules = makefile.rules().collect::<Vec<_>>();
        assert_eq!(rules.len(), 1);
        assert_eq!(rules[0].targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(rules[0].prerequisites().collect::<Vec<_>>(), vec!["$(DEP)"]);
        assert_eq!(rules[0].recipes().collect::<Vec<_>>(), vec!["command"]);
    }

    #[test]
    fn test_parse_with_variable_command() {
        let makefile =
            Makefile::from_reader("COM := command\nrule: dependency\n\t$(COM)".as_bytes()).unwrap();

        // Check variable definition
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 1);
        assert_eq!(vars[0].name(), Some("COM".to_string()));
        assert_eq!(vars[0].raw_value(), Some("command".to_string()));

        // Check rule
        let rules = makefile.rules().collect::<Vec<_>>();
        assert_eq!(rules.len(), 1);
        assert_eq!(rules[0].targets().collect::<Vec<_>>(), vec!["rule"]);
        assert_eq!(
            rules[0].prerequisites().collect::<Vec<_>>(),
            vec!["dependency"]
        );
        assert_eq!(rules[0].recipes().collect::<Vec<_>>(), vec!["$(COM)"]);
    }

    #[test]
    fn test_regular_line_error_reporting() {
        let input = "rule target\n\tcommand";

        // Test both APIs with one input
        let parsed = parse(input);
        let direct_error = &parsed.errors[0];

        // Verify error is detected with correct details
        assert_eq!(direct_error.line, 2);
        assert_eq!(direct_error.message, "expected ':'");
        assert_eq!(direct_error.context, "\tcommand");

        // Check public API
        let reader_result = Makefile::from_reader(input.as_bytes());
        let parse_error = match reader_result {
            Ok(_) => panic!("Expected Parse error from from_reader"),
            Err(err) => match err {
                self::Error::Parse(parse_err) => parse_err,
                _ => panic!("Expected Parse error"),
            },
        };

        // Verify formatting includes line number and context
        let error_text = parse_error.to_string();
        assert!(error_text.contains("Error at line 2:"));
        assert!(error_text.contains("2| \tcommand"));
    }

    #[test]
    fn test_parsing_error_context_with_bad_syntax() {
        // Test with unusual characters to ensure they're preserved
        let input = "#begin comment\n\t(╯°□°)╯︵ ┻━┻\n#end comment";
        println!("Input: {:?}", input);
        println!("Line count: {}", input.lines().count());
        for (i, line) in input.lines().enumerate() {
            println!("Line {}: {:?}", i + 1, line);
            if line.starts_with('\t') {
                println!("Found tab on line {}", i + 1);
            }
        }

        let reader_error = match Makefile::from_reader(input.as_bytes()) {
            Ok(_) => panic!("Expected error"),
            Err(err) => match err {
                self::Error::Parse(error) => {
                    println!("Error: {:?}", error);
                    println!("Error line: {}", error.errors[0].line);
                    println!("Error context: {:?}", error.errors[0].context);
                    error
                }
                _ => panic!("Expected Parse error"),
            },
        };

        // Line number is 3 (where the indented line is)
        assert_eq!(reader_error.errors[0].line, 3);
        assert_eq!(reader_error.errors[0].context, "#end comment");
    }

    #[test]
    fn test_error_message_format() {
        // Test the error formatter directly
        let parse_error = ParseError {
            errors: vec![ErrorInfo {
                message: "test error".to_string(),
                line: 42,
                context: "some problematic code".to_string(),
            }],
        };

        let error_text = parse_error.to_string();
        assert!(error_text.contains("Error at line 42: test error"));
        assert!(error_text.contains("42| some problematic code"));
    }

    #[test]
    fn test_line_number_calculation() {
        // Test various locations for errors
        let test_cases = [
            ("rule dependency\n\tcommand", 2),
            ("#comment\n\t(╯°□°)╯︵ ┻━┻", 2),
            ("var = value\n#comment\n\tindented line", 3),
        ];

        for (input, expected_line) in test_cases {
            println!("Testing input: {:?}", input);

            // From the FromStr implementation, we expect ParseError directly
            let parsed = match input.parse::<Makefile>() {
                Ok(_) => panic!("Expected parse error"),
                Err(err) => err, // err is already a ParseError
            };

            println!("Error message: {}", parsed.errors[0].message);
            println!(
                "Error line: {}, expected: {}",
                parsed.errors[0].line, expected_line
            );
            println!("Error context: {:?}", parsed.errors[0].context);

            assert_eq!(parsed.errors[0].line, expected_line);
            assert!(
                parsed.errors[0].context.starts_with('\t'),
                "Context should include the tab character"
            );
        }
    }

    #[test]
    fn test_parse_simple_conditional() {
        let parsed = parse("ifdef DEBUG\n    DEBUG_FLAG := 1\nendif\n");
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert!(format!("{:#?}", node).contains("CONDITIONAL@"));
    }

    #[test]
    fn test_parse_makefile_conditional() {
        let parsed = parse(
            "ifeq ($(OS),Windows_NT)\n    RESULT := windows\nelse\n    RESULT := unix\nendif\n",
        );
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert!(format!("{:#?}", node).contains("CONDITIONAL@"));
    }

    #[test]
    fn test_nested_conditionals() {
        let parsed = parse("ifdef DEBUG\n    CFLAGS += -g\n    ifdef VERBOSE\n        CFLAGS += -v\n    endif\nelse\n    CFLAGS += -O2\nendif\n");
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        let node_debug = format!("{:#?}", node);
        assert!(node_debug.contains("CONDITIONAL@"));
        assert!(node_debug.matches("DEBUG").count() >= 1);
        assert!(node_debug.matches("VERBOSE").count() >= 1);
    }

    #[test]
    fn test_include_directive() {
        let parsed = parse("include config.mk\ninclude $(TOPDIR)/rules.mk\ninclude *.mk\n");
        assert!(parsed.errors.is_empty());
        let node = parsed.syntax();
        assert!(format!("{:#?}", node).contains("INCLUDE@"));
    }

    #[test]
    fn test_export_variables() {
        let parsed = parse("export SHELL := /bin/bash\n");
        assert!(parsed.errors.is_empty());
        let makefile = parsed.root();
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 1);
        let shell_var = vars
            .iter()
            .find(|v| v.name() == Some("SHELL".to_string()))
            .unwrap();
        assert!(shell_var.raw_value().unwrap().contains("bin/bash"));
    }

    #[test]
    fn test_variable_scopes() {
        let parsed =
            parse("SIMPLE = value\nIMMEDIATE := value\nCONDITIONAL ?= value\nAPPEND += value\n");
        assert!(parsed.errors.is_empty());
        let makefile = parsed.root();
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 4);
        let var_names: Vec<_> = vars.iter().filter_map(|v| v.name()).collect();
        assert!(var_names.contains(&"SIMPLE".to_string()));
        assert!(var_names.contains(&"IMMEDIATE".to_string()));
        assert!(var_names.contains(&"CONDITIONAL".to_string()));
        assert!(var_names.contains(&"APPEND".to_string()));
    }

    #[test]
    fn test_complex_variable_references() {
        let parsed = parse("FILES := $(wildcard *.c)\nOBJS := $(patsubst %.c,%.o,$(FILES))\n");
        assert!(parsed.errors.is_empty());
        let makefile = parsed.root();
        let vars = makefile.variable_definitions().collect::<Vec<_>>();
        assert_eq!(vars.len(), 2);
        let var_names: Vec<_> = vars.iter().filter_map(|v| v.name()).collect();
        assert!(var_names.contains(&"FILES".to_string()));
        assert!(var_names.contains(&"OBJS".to_string()));
    }

    #[test]
    fn test_pattern_rule_parsing() {
        let parsed = parse("%.o: %.c\n\t$(CC) -c -o $@ $<\n");
        assert!(parsed.errors.is_empty());
        let makefile = parsed.root();
        let rules = makefile.rules().collect::<Vec<_>>();
        assert_eq!(rules.len(), 1);
        assert_eq!(rules[0].targets().next().unwrap(), "%.o");
        assert!(rules[0].recipes().next().unwrap().contains("$@"));
    }

    #[test]
    fn test_include_variants() {
        // Test all variants of include directives
        let makefile_str = "include simple.mk\n-include optional.mk\nsinclude synonym.mk\ninclude $(VAR)/generated.mk\n";
        let parsed = parse(makefile_str);
        assert!(parsed.errors.is_empty());

        // Get the syntax tree for inspection
        let node = parsed.syntax();
        let debug_str = format!("{:#?}", node);

        // Check that all includes are correctly parsed as INCLUDE nodes
        assert_eq!(debug_str.matches("INCLUDE@").count(), 4);

        // Check that we can access the includes through the AST
        let makefile = parsed.root();

        // Count all child nodes that are INCLUDE kind
        let include_count = makefile
            .syntax()
            .children()
            .filter(|child| child.kind() == INCLUDE)
            .count();
        assert_eq!(include_count, 4);

        // Test variable expansion in include paths
        assert!(makefile
            .included_files()
            .any(|path| path.contains("$(VAR)")));
    }

    #[test]
    fn test_include_api() {
        // Test the API for working with include directives
        let makefile_str = "include simple.mk\n-include optional.mk\nsinclude synonym.mk\n";
        let makefile: Makefile = makefile_str.parse().unwrap();

        // Test the includes method
        let includes: Vec<_> = makefile.includes().collect();
        assert_eq!(includes.len(), 3);

        // Test the is_optional method
        assert!(!includes[0].is_optional()); // include
        assert!(includes[1].is_optional()); // -include
        assert!(includes[2].is_optional()); // sinclude

        // Test the included_files method
        let files: Vec<_> = makefile.included_files().collect();
        assert_eq!(files, vec!["simple.mk", "optional.mk", "synonym.mk"]);

        // Test the path method on Include
        assert_eq!(includes[0].path(), Some("simple.mk".to_string()));
        assert_eq!(includes[1].path(), Some("optional.mk".to_string()));
        assert_eq!(includes[2].path(), Some("synonym.mk".to_string()));
    }

    #[test]
    fn test_include_integration() {
        // Test include directives in realistic makefile contexts

        // Case 1: With .PHONY (which was a source of the original issue)
        let phony_makefile = Makefile::from_reader(
            ".PHONY: build\n\nVERBOSE ?= 0\n\n# comment\n-include .env\n\nrule: dependency\n\tcommand"
            .as_bytes()
        ).unwrap();

        // We expect 2 rules: .PHONY and rule
        assert_eq!(phony_makefile.rules().count(), 2);

        // But only one non-special rule (not starting with '.')
        let normal_rules_count = phony_makefile
            .rules()
            .filter(|r| !r.targets().any(|t| t.starts_with('.')))
            .count();
        assert_eq!(normal_rules_count, 1);

        // Verify we have the include directive
        assert_eq!(phony_makefile.includes().count(), 1);
        assert_eq!(phony_makefile.included_files().next().unwrap(), ".env");

        // Case 2: Without .PHONY, just a regular rule and include
        let simple_makefile = Makefile::from_reader(
            "\n\nVERBOSE ?= 0\n\n# comment\n-include .env\n\nrule: dependency\n\tcommand"
                .as_bytes(),
        )
        .unwrap();
        assert_eq!(simple_makefile.rules().count(), 1);
        assert_eq!(simple_makefile.includes().count(), 1);
    }
}
